# **Балансировка**

**1. Основная концепция**  
Балансировка нагрузки (Load Balancing) — это распределение входящего сетевого трафика между несколькими серверами. Это нужно для:  
- Оптимизации использования ресурсов  
- Увеличения отказоустойчивости  
- Улучшения масштабируемости  
- Снижения задержки для пользователей  

**2. Где применяется?**  
- Веб-приложения (HTTP/HTTPS)  
- Микросервисные архитектуры  
- Базы данных (репликация, шардирование)  
- Потоковые сервисы (видео, аудио)  

**3. Алгоритмы балансировки**  
- **Round Robin** — поочерёдное распределение запросов (просто, но без учёта нагрузки)  
- **Weighted Round Robin** — как Round Robin, но с приоритетами (весами)  
- **Least Connections** — отправка запроса на сервер с наименьшим числом активных соединений  
- **IP Hash** — привязка клиента к определённому серверу (полезно для сессий)  
- **Least Response Time** — выбор сервера с наименьшей задержкой  

**4. Уровни балансировки**  
- **L4 (Transport Layer)** — балансировка на уровне TCP/UDP (например, Nginx, HAProxy в режиме L4)  
- **L7 (Application Layer)** — "умная" балансировка, учитывающая HTTP-заголовки, cookies (например, Nginx, HAProxy, AWS ALB)  

**5. Инструменты и технологии**  
- **Nginx** — мощный балансировщик L7 с гибкой конфигурацией  
- **HAProxy** — популярен для высоконагруженных систем, поддерживает L4 и L7  
- **Cloud-решения** — AWS ALB/NLB, Google Cloud Load Balancer, Azure Load Balancer  
- **Kubernetes Ingress** — балансировка в кластерах Kubernetes  

**6. Отказоустойчивость и health checks**  
Балансировщики должны проверять работоспособность серверов:  
- HTTP-проверки (GET /health)  
- TCP-проверки (доступен ли порт)  
- Время отклика (timeout)  

**7. Сессии и sticky sessions**  
Если приложение stateful (например, корзина в интернет-магазине), важно, чтобы запросы пользователя попадали на один и тот же сервер. Решения:  
- Куки (например, `JSESSIONID`)  
- IP-привязка  

**8. Кэширование и SSL/TLS терминация**  
Балансировщик может:  
- Разгружать серверы, обрабатывая SSL-шифрование  
- Кэшировать статику (например, Nginx)  

**9. Горизонтальное vs вертикальное масштабирование**  
Балансировка связана с горизонтальным масштабированием (добавление серверов), а не вертикальным (увеличение мощности одного сервера).  

---

### **1. "Как бы ты настроил балансировщик для API с высокой нагрузкой?"**  
**Подход:**  
- **Выбор балансировщика:** HAProxy или Nginx (L7 для HTTP API), либо cloud-решение (AWS ALB, если инфраструктура в AWS).  
- **Алгоритм балансировки:**  
  - Если API stateless → **Least Connections** (оптимально для равномерного распределения).  
  - Если есть локальные кэши/сессии → **IP Hash** или **sticky sessions** (но это усложняет масштабирование).  
- **Health Checks:**  
  - `/health` эндпоинт с проверкой 200 OK.  
  - Интервал: 5–10 сек (чтобы быстро исключать нерабочие ноды).  
- **Терминация SSL:**  
  - Разгрузить бэкенды, обрабатывая HTTPS на балансировщике.  
- **Кэширование:**  
  - Если API имеет "тяжёлые" GET-запросы → кэшировать ответы на балансировщике (Nginx).  
- **Резервные серверы:**  
  - Настроить `backup`-ноды в HAProxy, которые включаются при падении основных.  
- **Логирование и мониторинг:**  
  - Сбор метрик (RPS, latency, ошибки 5xx) в Prometheus + Grafana.  

**Пример для HAProxy:**  
```haproxy
backend api_servers
    balance leastconn
    server api1 10.0.0.1:8080 check inter 5s
    server api2 10.0.0.2:8080 check inter 5s
    option httpchk GET /health
```

---

### **2. "Какие метрики важно мониторить при балансировке?"**  
**Ключевые метрики:**  
- **Сетевые:**  
  - **Пропускная способность** (throughput) — сколько запросов в секунду (RPS).  
  - **Задержка** (latency) — p50, p90, p99 (резкие скачки = проблемы).  
- **Серверные:**  
  - **Загрузка CPU** (если 70–80% → пора масштабироваться).  
  - **Потребление памяти** (OOM Killer может убивать процессы).  
  - **Количество соединений** (в HAProxy: `session_current`).  
- **Ошибки:**  
  - **HTTP-коды** (5xx — серверные ошибки, 4xx — клиентские).  
  - **Таймауты** (connection timeout, read timeout).  
- **Эффективность балансировки:**  
  - Равномерность распределения запросов (нет ли "перекоса" на 1 сервер).  
  - **Rate limiting** (если настроен) — количество отклонённых запросов.  

**Инструменты:**  
- Prometheus + Grafana (метрики).  
- ELK Stack (логи).  
- CloudWatch (для AWS).  

---

### **3. "Как обеспечить минимальный downtime при развёртывании нового кода?"**  
**Стратегии:**  
- **Blue-Green Deployment:**  
  - Два идентичных кластера ("blue" и "green").  
  - Развёртывание на "green", тестирование, переключение трафика (DNS или балансировщик).  
  - Даунтайм = 0, но требует 2x ресурсов.  
- **Canary-развёртывание:**  
  - Постепенный перевод трафика на новую версию (например, 5% → 50% → 100%).  
  - Если есть ошибки — откат.  
- **Rolling Update (Kubernetes):**  
  - Постепенная замена подов (подами управляет Deployment).  
  - `maxSurge: 25%`, `maxUnavailable: 0` (чтобы не терять доступность).  

**Технические детали:**  
- **Graceful Shutdown:**  
  - Сервер должен завершать активные соединения перед остановкой (SIGTERM → завершить работу за N секунд → SIGKILL).  
- **Readiness/Liveness Probes (K8s):**  
  - Бекенд должен сообщать балансировщику, когда он готов принимать трафик.  
- **Сброс соединений (Drain):**  
  - HAProxy: `disable server` перед остановкой.  
  - Nginx: `nginx -s reload` (без разрыва соединений).  

**Пример для Kubernetes:**  
```yaml
spec:
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
```

---

### **Что ещё могут спросить?**  
- "Как обрабатывать внезапный всплеск трафика?" → Автоскейлинг + Rate Limiting.  
- "В чём разница между ALB и NLB в AWS?" → L7 vs L4, features.  
- "Как debug-ить проблемы с балансировкой?" → Логи + `tcpdump` + метрики.  

# **Nginx: назначение, отказоустойчивость, мониторинг и траблшутинг**  

Nginx — это высокопроизводительный **веб-сервер**, **обратный прокси** и **балансировщик нагрузки**, который широко используется в высоконагруженных системах (YouTube, Netflix, Cloudflare).  

---

## **1. Назначение Nginx**  
### **Основные функции:**  
- **Веб-сервер**  
  - Отдача статики (HTML, CSS, JS, изображения) — работает быстрее Apache за счёт асинхронной архитектуры.  
  - Поддержка HTTP/2 и HTTPS (шифрование через OpenSSL).  
- **Обратный прокси (Reverse Proxy)**  
  - Перенаправление запросов к бэкендам (например, Python/Node.js приложениям).  
  - Терминация SSL (разгрузка бэкендов).  
  - Кэширование ответов.  
- **Балансировщик нагрузки (Load Balancer)**  
  - Распределение трафика между серверами (Round Robin, Least Connections, IP Hash).  
  - Поддержка health checks.  

### **Почему выбирают Nginx?**  
- Высокая производительность (обрабатывает десятки тысяч соединений с малым потреблением CPU).  
- Гибкая конфигурация.  
- Модульность (можно расширять через Lua-скрипты или сторонние модули).  

---

## **2. Отказоустойчивость (High Availability)**  
Nginx сам по себе не обеспечивает полную отказоустойчивость, но его можно настроить для минимизации downtime:  

### **Способы повышения надёжности:**  
1. **Кластеризация Nginx (Active-Passive или Active-Active)**  
   - **Active-Passive**: Один Nginx работает, второй в режиме hot standby (используется Keepalived для переключения при падении).  
   - **Active-Active**: Несколько Nginx балансируют трафик (например, за DNS-распределением).  

2. **Health Checks для бэкендов**  
   ```nginx
   upstream backend {
       server 10.0.0.1:8000 max_fails=3 fail_timeout=30s;
       server 10.0.0.2:8000 backup;  # резервный сервер
   }
   ```
   - `max_fails` — сколько ошибок подряд считать сервер "упавшим".  
   - `fail_timeout` — время, через которое повторить проверку.  

3. **Graceful Restart**  
   - Перезагрузка конфига без разрыва соединений:  
     ```bash
     nginx -s reload
     ```
   - Graceful Shutdown (завершение активных соединений перед остановкой).  

4. **Резервирование через Cloud (AWS ALB + Nginx)**  
   - Если Nginx развёрнут в облаке, можно использовать AWS ALB как первичный балансировщик, а Nginx — для дополнительного кэширования.  

---

## **3. Мониторинг Nginx**  
### **Что мониторить?**  
- **Основные метрики:**  
  - **Active connections** — количество активных соединений.  
  - **Requests per second (RPS)** — нагрузка.  
  - **Response time** — время ответа (p50, p90, p99).  
  - **Error rates** — 4xx, 5xx ошибки.  
  - **Traffic** — входящий/исходящий трафик.  

### **Инструменты:**  
1. **Nginx Status Module (stub_status)**  
   ```nginx
   server {
       listen 80;
       server_name localhost;
       location /nginx_status {
           stub_status on;
           allow 127.0.0.1;  # только для внутреннего мониторинга
           deny all;
       }
   }
   ```
   Вывод:  
   ```
   Active connections: 291
   server accepts handled requests
   16630948 16630948 31070465
   Reading: 6 Writing: 179 Waiting: 106
   ```  

2. **Prometheus + Grafana**  
   - Используется **nginx-prometheus-exporter** для сбора метрик.  
   - Дашборды в Grafana для визуализации.  

3. **ELK Stack (логирование)**  
   - Анализ `access.log` и `error.log` через Logstash + Elasticsearch.  

4. **Cloud-решения (AWS CloudWatch, Datadog)**  
   - Готовые интеграции для мониторинга.  

---

## **4. Траблшутинг (поиск и устранение проблем)**  
### **Частые проблемы и решения:**  

#### **1. Высокая загрузка CPU**  
- **Причины:**  
  - Слишком много запросов.  
  - Неоптимальные конфиги (например, отсутствие кэширования).  
  - DDoS-атака.  
- **Решение:**  
  - Проверить `top` / `htop` → какие процессы грузят CPU.  
  - Настроить rate limiting:  
    ```nginx
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=100r/s;
    ```  
  - Включить кэширование статики:  
    ```nginx
    location ~* \.(jpg|css|js)$ {
        expires 30d;
        add_header Cache-Control "public";
    }
    ```  

#### **2. Медленные ответы от бэкендов**  
- **Причины:**  
  - Перегружены backend-серверы.  
  - Проблемы с сетью.  
- **Решение:**  
  - Увеличить таймауты:  
    ```nginx
    proxy_connect_timeout 5s;
    proxy_read_timeout 30s;
    ```  
  - Проверить логи бэкендов (например, slow queries в БД).  

#### **3. 502 Bad Gateway**  
- **Причины:**  
  - Бэкенд не отвечает.  
  - Неправильные proxy-настройки.  
- **Решение:**  
  - Проверить `error.log` Nginx.  
  - Убедиться, что бэкенд доступен:  
    ```bash
    curl -v http://backend:8000/health
    ```  

#### **4. Утечки памяти**  
- **Причины:**  
  - Неправильно настроенные буферы.  
  - Модули, потребляющие память (например, Lua-скрипты).  
- **Решение:**  
  - Мониторить `nginx -V` (какие модули подключены).  
  - Проверить настройки буферов:  
    ```nginx
    proxy_buffer_size 4k;
    proxy_buffers 8 16k;
    ```  

---

# **HAProxy: назначение, отказоустойчивость, мониторинг и траблшутинг**  

HAProxy (High Availability Proxy) — это **высокопроизводительный балансировщик нагрузки** и **обратный прокси**, специализирующийся на распределении TCP/HTTP-трафика. Широко используется в высоконагруженных системах (GitLab, GitHub, Reddit, Instagram).  

---

## **1. Назначение HAProxy**  
### **Основные функции:**  
- **Балансировка нагрузки (L4 и L7)**  
  - Поддержка HTTP, HTTPS, TCP (например, для баз данных, RabbitMQ, WebSocket).  
  - Алгоритмы: Round Robin, Least Connections, Source IP Hash и др.  
- **Обратный прокси**  
  - Перенаправление запросов на бэкенд-серверы.  
  - Терминация SSL (разгрузка бэкендов).  
- **Высокая доступность (High Availability)**  
  - Поддержка health checks и автоматическое исключение нерабочих серверов.  
- **Безопасность**  
  - Защита от DDoS (rate limiting, ACL).  
  - Поддержка TLS 1.3.  

### **Почему выбирают HAProxy?**  
- **Высокая производительность** (обрабатывает миллионы запросов в секунду).  
- **Гибкость** (тонкая настройка балансировки, ACL, Lua-скрипты).  
- **Стабильность** (используется в критически важных системах).  

---

## **2. Отказоустойчивость (High Availability)**  
### **Способы обеспечения отказоустойчивости:**  
1. **Active-Passive с Keepalived**  
   - Два HAProxy-сервера: один активный, второй в режиме горячего резерва.  
   - Виртуальный IP (VIP) переключается при падении основного сервера.  

   **Пример настройки Keepalived:**  
   ```conf
   vrrp_instance VI_1 {
       state MASTER
       interface eth0
       virtual_router_id 51
       priority 100
       advert_int 1
       virtual_ipaddress {
           192.168.1.100/24
       }
   }
   ```  

2. **Active-Active с DNS-балансировкой**  
   - Несколько HAProxy-серверов за DNS Round Robin (например, в облаке AWS).  

3. **Health Checks**  
   - Автоматическое исключение нерабочих серверов:  
     ```haproxy
     backend web_servers
         balance roundrobin
         server web1 10.0.0.1:80 check inter 5s fall 3 rise 2
         server web2 10.0.0.2:80 check backup  # резервный сервер
     ```  
     - `inter 5s` — проверка каждые 5 секунд.  
     - `fall 3` — сервер считается "мёртвым" после 3 ошибок.  
     - `rise 2` — сервер возвращается в строй после 2 успешных проверок.  

4. **Graceful Shutdown**  
   - Перед остановкой HAProxy завершает активные соединения:  
     ```bash
     haproxy -sf $(cat /var/run/haproxy.pid)  # плавный restart
     ```  

---

## **3. Мониторинг HAProxy**  
### **Что мониторить?**  
- **Основные метрики:**  
  - **Active connections** — текущие соединения.  
  - **Request rate (RPS)** — запросы в секунду.  
  - **Response time** — время ответа бэкендов.  
  - **Error rates** — количество 4xx/5xx ошибок.  
  - **Queue size** — если запросы начинают накапливаться.  

### **Инструменты:**  
1. **HAProxy Stats (встроенный мониторинг)**  
   ```haproxy
   listen stats
       bind *:8404
       stats enable
       stats uri /haproxy?stats
       stats refresh 10s
       stats admin if TRUE  # доступ к управлению
   ```  
   Доступ через `http://haproxy-server:8404/haproxy?stats`.  

2. **Prometheus + Grafana**  
   - Используется **haproxy_exporter** для сбора метрик.  
   - Пример дашборда: [HAProxy Grafana Dashboard](https://grafana.com/grafana/dashboards/367).  

3. **ELK Stack (логирование)**  
   - Анализ логов HAProxy (`/var/log/haproxy.log`).  

4. **Cloud-решения (Datadog, AWS CloudWatch)**  
   - Готовые интеграции для мониторинга.  

---

## **4. Траблшутинг (поиск и устранение проблем)**  
### **Частые проблемы и решения:**  

#### **1. HAProxy не запускается**  
- **Причины:**  
  - Ошибки в конфиге (`/etc/haproxy/haproxy.cfg`).  
  - Занятый порт.  
- **Решение:**  
  ```bash
  haproxy -c -f /etc/haproxy/haproxy.cfg  # проверка конфига
  netstat -tulnp | grep 80               # проверка занятых портов
  ```  

#### **2. Высокая загрузка CPU**  
- **Причины:**  
  - Атака (DDoS).  
  - Неоптимальные алгоритмы балансировки.  
- **Решение:**  
  - Включить rate limiting:  
    ```haproxy
    frontend http_in
        bind *:80
        acl too_fast sc0_http_req_rate gt 100
        tcp-request content reject if too_fast
    ```  
  - Сменить алгоритм балансировки (например, на `leastconn`).  

#### **3. 503 Service Unavailable**  
- **Причины:**  
  - Все бэкенды "умерли" (не проходят health checks).  
  - Закончились свободные слоты подключений (`maxconn`).  
- **Решение:**  
  - Проверить `haproxy stats` (какие серверы доступны).  
  - Увеличить `maxconn`:  
    ```haproxy
    defaults
        maxconn 5000
    ```  

#### **4. Медленные ответы от бэкендов**  
- **Причины:**  
  - Перегружены backend-серверы.  
  - Проблемы с сетью.  
- **Решение:**  
  - Настроить таймауты:  
    ```haproxy
    timeout connect 5s
    timeout server 30s
    ```  
  - Проверить логи бэкендов (например, медленные SQL-запросы).  

#### **5. Проблемы с SSL**  
- **Причины:**  
  - Устаревшие сертификаты.  
  - Неправильные настройки TLS.  
- **Решение:**  
  - Проверить сертификаты:  
    ```bash
    openssl s_client -connect example.com:443
    ```  
  - Оптимизировать TLS-настройки:  
    ```haproxy
    bind *:443 ssl crt /etc/haproxy/certs/example.pem alpn h2,http/1.1
    ssl-default-bind-ciphers TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256
    ```  

---
